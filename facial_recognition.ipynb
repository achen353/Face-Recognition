{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "* Run the program (including building the database):\n",
    "    * 1.1 --> 2.1 --> 3.1 --> 3.2 --> 3.3 --> 3.4 (YouTube) or 3.5 (Web Cam) --> 4.2 --> 4.3 --> 5.2 --> 5.3\n",
    "* Run face recognition with pre-built database:\n",
    "    * 1.1 --> 2.1 --> 4.2 --> 4.3 --> 5.2 --> 5.3\n",
    "* Database building only: \n",
    "    * 1.1 --> 2.1 --> 3.1 --> 3.2 --> 3.3 --> 3.4\n",
    "    \n",
    "Each block is elaborated as commented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and packages needed\n",
    "import sys, os, dlib, glob, pickle, face_recognition, cv2, random, imutils, csv, pafy\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create label collection: subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the directories (one directory for each subject) in data folder\n",
    "out_dir = \"./training-data\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "dirs = os.listdir(out_dir)\n",
    "\n",
    "#initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "#there is no label 0 in our training data so subject name for index/label 0 is empty\n",
    "subject_csv_dir = \"./subjects.csv\"\n",
    "subjects = [\"\"]\n",
    "#import subjects from existing csv file (if any) to continue the list\n",
    "if os.path.exists(subject_csv_dir):\n",
    "    with open('./subjects.csv') as subjects_csv:\n",
    "        reader = csv.reader(subjects_csv, delimiter=\",\")\n",
    "        subjects = list(reader)[0]\n",
    "        print(\"[INFO] CSV file read.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Collect Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison on different face detection:\n",
    "\n",
    "https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 relight() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改變亮度與對比\n",
    "def relight(img,alpha = 1,bias = 0):\n",
    "    w, h = img.shape[:2]\n",
    "\n",
    "    for i in range(0,w):\n",
    "        for j in range(0,h):\n",
    "            for c in range(3):\n",
    "                tmp = int(img[i,j,c] * alpha + bias)\n",
    "                if tmp > 255:\n",
    "                    tmp = 255\n",
    "                elif tmp < 0:\n",
    "                    tmp = 0\n",
    "                img[i,j,c] = tmp\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Input specifics of data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input number of subject\n",
    "while True:\n",
    "    try:\n",
    "        num_of_subject = int(input(\"Enter the number of subject(s): \"))\n",
    "    except ValueError:\n",
    "        print(\"Try again.\")\n",
    "        continue\n",
    "    if num_of_subject <= 0:\n",
    "        print(\"Negative number not accepted.\")\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#choose data capture method\n",
    "while True:\n",
    "    try:\n",
    "        method_choice = int(input(\"Enter (1) YouTube or (2) Web Cam: \"))\n",
    "    except ValueError:\n",
    "        print(\"Try again.\")\n",
    "        continue\n",
    "    if method_choice != 1 and method_choice != 2:\n",
    "        print(\"Must enter 1 or 2.\")\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Import model and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set cropping size for the images captured\n",
    "crop_size = 128\n",
    "\n",
    "#check if there's any label/face in the collection already\n",
    "collection_size = len(subjects)\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] Loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "print(\"[INFO] Model loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Capture images from YouTube video (run this if method_choice == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method_choice == 1:\n",
    "    print(\"[INFO] Capturing images...\")\n",
    "\n",
    "    #iterate through the subject\n",
    "    for i in range(num_of_subject):\n",
    "\n",
    "        #input subject name and append it to subjects\n",
    "        subject_name = input(\"Enter name for Subject #\" + str(i + collection_size) + \": \")\n",
    "        start_num = 0\n",
    "\n",
    "        #input youtube video URL\n",
    "        while True:\n",
    "            try:\n",
    "                # set up video stream capture\n",
    "                url = input(\"Enter YouTube URL: \")\n",
    "                video = pafy.new(url)\n",
    "                best = video.getbest(preftype = \"mp4\")\n",
    "                cap = cv2.VideoCapture()\n",
    "                cap.open(best.url)\n",
    "                framerate = cap.get(cv2.CAP_PROP_FPS)\n",
    "                video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                multipler = int(framerate * 5)\n",
    "            except Exception:\n",
    "                print(\"Try again.\")\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        #if the input exists in subjects, no new entry will be appended\n",
    "        if subject_name in subjects:\n",
    "            subject_dir = out_dir + \"/s\" + str(subjects.index(subject_name))\n",
    "            sub_dir_obj = os.fsencode(subject_dir)\n",
    "            #iterate through the file names to find the correct starting index for new inputs\n",
    "            if len(os.listdir(sub_dir_obj) ) == 0:\n",
    "                break;\n",
    "            else:\n",
    "                for file in os.listdir(sub_dir_obj):\n",
    "                    if file is not '':\n",
    "                        file_name_str = os.fsdecode(file).split('.')\n",
    "                        file_num = int(file_name_str[0])\n",
    "                        start_num = max(file_num, start_num)\n",
    "                start_num += 1   \n",
    "        #append new entry to subjects and create respective directory \n",
    "        else:\n",
    "            subjects.append(subject_name)\n",
    "            #create folder for each subject (if not exist)\n",
    "            subject_dir = out_dir + \"/s\" + str(i + collection_size)\n",
    "            if not os.path.exists(subject_dir):\n",
    "                os.makedirs(subject_dir)\n",
    "        \n",
    "        #capture images of the subject until target number reached\n",
    "        n = 1\n",
    "        count = 0\n",
    "        print(\"[INFO] Capturing the face of Subject #\" + str(i + collection_size) + \"...\")\n",
    "        print(\"Video Length: \" + str(int(video_length)))\n",
    "\n",
    "        while(cap.isOpened()):  #check!\n",
    "            #capture frame-by-frame\n",
    "            if count < int(video_length):\n",
    "                ret, image = cap.read()\n",
    "                count += 1\n",
    "                if count % multipler == 0:\n",
    "                    print('Processing Image %s...' % str(n))\n",
    "                    print('Frame ' + str(count))\n",
    "\n",
    "                    #load the input image and construct an input blob for the image by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "                    (h, w) = image.shape[:2]\n",
    "                    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "                    #pass the blob through the network and obtain the detections and predictions\n",
    "                    print(\"[INFO] Computing object detections...\")\n",
    "                    net.setInput(blob)\n",
    "                    detections = net.forward()\n",
    "\n",
    "                    #loop over the detections\n",
    "                    for i in range(0, detections.shape[2]):\n",
    "                        #extract the confidence (i.e., probability) associated with the prediction\n",
    "                        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                        #filter out weak detections by ensuring the 'confidence' is greater than the minimum confidence\n",
    "                        if confidence > 0.95:\n",
    "                            #compute the (x, y)-coordinates of the bounding box for the object\n",
    "                            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                            face = image[startY : endY, startX : endX]\n",
    "                            width, height, channels = face.shape\n",
    "                            if min(width, height) > 128:\n",
    "                                face = cv2.resize(face,(crop_size, crop_size))\n",
    "\n",
    "                            face = relight(face,random.uniform(0.5,1.5),random.randint(-50,50))\n",
    "                            cv2.imwrite(subject_dir + '/' + str(n + start_num) + '.jpg', face)\n",
    "                            print('Image %s processed.' % str(n))\n",
    "                            n += 1\n",
    "                    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "    cap.release()   \n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] Image Capture Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Capture images through web cam and detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method_choice == 2:\n",
    "    # set up web cam capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    #input number of images per subject\n",
    "    while True:\n",
    "        try:\n",
    "            image_per_subject = int(input(\"Enter the number of image per subject: \"))\n",
    "        except ValueError:\n",
    "            print(\"Try again.\")\n",
    "            continue\n",
    "        if image_per_subject <= 0:\n",
    "            print(\"Negative number not accepted.\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(\"[INFO] Capturing images...\")\n",
    "\n",
    "    #iterate through the subject\n",
    "    for i in range(num_of_subject):\n",
    "\n",
    "        #input subject name and append it to subjects\n",
    "        subject_name = input(\"Enter name for Subject #\" + str(i + collection_size) + \": \")\n",
    "        start_num = 0\n",
    "\n",
    "        #if the input exists in subjects, no new entry will be appended\n",
    "        if subject_name in subjects:\n",
    "            subject_dir = out_dir + \"/s\" + str(subjects.index(subject_name))\n",
    "            sub_dir_obj = os.fsencode(subject_dir)\n",
    "            #iterate through the file names to find the correct starting index for new inputs\n",
    "            if len(os.listdir(sub_dir_obj) ) == 0:\n",
    "                break;\n",
    "            else:\n",
    "                for file in os.listdir(sub_dir_obj):\n",
    "                    if file is not '':\n",
    "                        file_name_str = os.fsdecode(file).split('.')\n",
    "                        file_num = int(file_name_str[0])\n",
    "                        start_num = max(file_num, start_num)\n",
    "                start_num += 1   \n",
    "        #append new entry to subjects and create respective directory \n",
    "        else:\n",
    "            subjects.append(subject_name)\n",
    "            #create folder for each subject (if not exist)\n",
    "            subject_dir = out_dir + \"/s\" + str(i + collection_size)\n",
    "            if not os.path.exists(subject_dir):\n",
    "                os.makedirs(subject_dir)\n",
    "\n",
    "        #capture images of the subject until target number reached\n",
    "        n = 1\n",
    "        print(\"[INFO] Capturing the face of Subject #\" + str(i + collection_size) + \"...\")\n",
    "        while(cap.isOpened()):  # check !\n",
    "            # capture frame-by-frame  \n",
    "            if n <= image_per_subject:\n",
    "                ret, image = cap.read()\n",
    "                print('Processing Image %s...' % str(n))\n",
    "\n",
    "                # load the input image and construct an input blob for the image by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "                (h, w) = image.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "                # pass the blob through the network and obtain the detections and predictions\n",
    "                print(\"[INFO] Computing object detections...\")\n",
    "                net.setInput(blob)\n",
    "                detections = net.forward()\n",
    "\n",
    "                # loop over the detections\n",
    "                for i in range(0, detections.shape[2]):\n",
    "                    # extract the confidence (i.e., probability) associated with the prediction\n",
    "                    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                    # filter out weak detections by ensuring the 'confidence' is greater than the minimum confidence\n",
    "                    if confidence > 0.95:\n",
    "                        # compute the (x, y)-coordinates of the bounding box for the object\n",
    "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                        face = image[startY : endY, startX : endX]\n",
    "                        width, height, channels = face.shape\n",
    "                        if min(width, height) > 128:\n",
    "                            face = cv2.resize(face,(crop_size, crop_size))\n",
    "\n",
    "                        face = relight(face,random.uniform(0.5,1.5),random.randint(-50,50))\n",
    "                        cv2.imwrite(subject_dir + '/' + str(n + start_num) + '.jpg', face)\n",
    "                        print('Image %s processed.' % str(n))\n",
    "                        n += 1\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    cap.release()   \n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] Image Capture Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare Training Data & Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Directory Structure Tree for Training Data:\n",
    "```\n",
    "training-data\n",
    "|-------------- s1\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "|-------------- s2\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "|-------------- sN\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 prepare_training_data() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #iterate through each subject's respective folder\n",
    "    for dir_name in dirs:\n",
    "\n",
    "        #ignore any directory not starting with 's'\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "\n",
    "        #extract label number by removing 's' in dir_name\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "        print(\"Training Subject #\" + str(label) + \": \")\n",
    "\n",
    "        #build path of directory containin images for current subject subject\n",
    "        #e.g. \"training-data/s1\"\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "\n",
    "        #get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "\n",
    "        for image_name in subject_images_names:\n",
    "            print(\"s\" + str(label) + \"/\" + image_name + \" completed.\")\n",
    "            \n",
    "            #create path to the image\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "            \n",
    "            # load the input image and convert it from BGR (OpenCV ordering)\n",
    "            # to dlib ordering (RGB)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue;\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # detect the (x, y)-coordinates of the bounding boxes\n",
    "            # corresponding to each face in the input image\n",
    "            boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
    "\n",
    "            # compute the facial embedding for the face\n",
    "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "            # loop over the encodings\n",
    "            for encoding in encodings:\n",
    "                # add each encoding + name to our set of known names and\n",
    "                # encodings\n",
    "                knownEncodings.append(encoding)\n",
    "                knownNames.append(subjects[label])\n",
    "    \n",
    "    data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prepare training data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Training model...\")\n",
    "data = prepare_training_data(\"./training-data\")\n",
    "print(\"[INFO] Model Training Completed.\")\n",
    "\n",
    "print(\"Total faces: \", len(data[\"encodings\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 recognize_faces() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(img_file):\n",
    "    \n",
    "    #load the input image and convert it from BGR to RGB\n",
    "    image = cv2.imread(img_file)\n",
    "    width, height, channels = image.shape\n",
    "    if min(width, height) > 1280:\n",
    "        image = imutils.resize(image, width = 1280)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #detect the (x, y)-coordinates of the bounding boxes corresponding \n",
    "    #to each face in the input image, then compute the facial embeddings for each face\n",
    "    print(\"[INFO] Recognizing faces...\")\n",
    "    boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "\n",
    "    #initialize the list of names for each face detected\n",
    "    names = []\n",
    "\n",
    "    #loop over the facial embeddings\n",
    "    for encoding in encodings:\n",
    "        #attempt to match each face in the input image to our known encodings\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        #check to see if we have found a match\n",
    "        if True in matches:\n",
    "            #find the indexes of all matched faces then initialize a dictionary \n",
    "            #to count the total number of times each face was matched\n",
    "            matchedIdxs = [i for (i, b) in enumerate (matches) if b]\n",
    "            counts = {}\n",
    "\n",
    "            #loop over the matched indexes and maintain a count for each recognized face face\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "            #determine the recognized face with the largest number of votes\n",
    "            #(note: in the event of an unlikely tie Python will select first entry in the dictionary)\n",
    "            name = max(counts, key=counts.get)\n",
    "\n",
    "        #update the list of names\n",
    "        names.append(name)\n",
    "    \n",
    "    #loop over the recognized faces\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        #draw the predicted face name on the image\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write subjects into csv file\n",
    "with open('subjects.csv', mode = 'w') as subject_file:\n",
    "    list_writer = csv.writer(subject_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    list_writer.writerow(subjects)\n",
    "\n",
    "#write data into csv file\n",
    "with open('data.csv', mode = 'w') as data_file:\n",
    "    fieldnames = [\"encodings\", \"names\"]\n",
    "    writer = csv.DictWriter(data_file, fieldnames = fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerow(data)\n",
    "print(\"[INFO] CSV files written.\")\n",
    "\n",
    "#recognize test image\n",
    "image = recognize_faces(\"test-data/test3.jpg\")\n",
    "print(\"[INFO] Recogonition Completed.\")\n",
    "\n",
    "#show the out put image \n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
