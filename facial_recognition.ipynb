{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and packages needed\n",
    "import sys, os, dlib, glob, pickle, face_recognition, cv2, random, imutils\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create label collection: subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the directories (one directory for each subject) in data folder\n",
    "out_dir = \"./training-data\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "dirs = os.listdir(out_dir)\n",
    "\n",
    "# initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "#there is no label 0 in our training data so subject name for index/label 0 is empty\n",
    "subjects = [\"\"]\n",
    "#subjects = [\"\", \"Hulk\", \"Iron Man\", \"Spider-man\", \"Thor\", \"Winter Soldier\", \"Ant-man\", \"Scarlet Witch\", \"Hawkeye\", \"Agent Sharon Carter\", \"Captain America\", \"Falcon\", \"Andrew Chen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Collect Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison on different face detection:\n",
    "\n",
    "https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 relight() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改變亮度與對比\n",
    "def relight(img,alpha = 1,bias = 0):\n",
    "    w, h = img.shape[:2]\n",
    "\n",
    "    for i in range(0,w):\n",
    "        for j in range(0,h):\n",
    "            for c in range(3):\n",
    "                tmp = int(img[i,j,c] * alpha + bias)\n",
    "                if tmp > 255:\n",
    "                    tmp = 255\n",
    "                elif tmp < 0:\n",
    "                    tmp = 0\n",
    "                img[i,j,c] = tmp\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Input specifics of data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of subject(s): 1\n",
      "Enter the number of image per subject: 30\n"
     ]
    }
   ],
   "source": [
    "#input number of subject\n",
    "while True:\n",
    "    try:\n",
    "        num_of_subject = int(input(\"Enter the number of subject(s): \"))\n",
    "    except ValueError:\n",
    "        print(\"Try again.\")\n",
    "        continue\n",
    "    if num_of_subject <= 0:\n",
    "        print(\"Negative number not accepted.\")\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#input number of images per subject\n",
    "while True:\n",
    "    try:\n",
    "        image_per_subject = int(input(\"Enter the number of image per subject: \"))\n",
    "    except ValueError:\n",
    "        print(\"Try again.\")\n",
    "        continue\n",
    "    if image_per_subject <= 0:\n",
    "        print(\"Negative number not accepted.\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Import model and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model...\n",
      "[INFO] Model loaded...\n"
     ]
    }
   ],
   "source": [
    "# set up video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#set cropping size for the images captured\n",
    "crop_size = 128\n",
    "\n",
    "#check if there's any label/face in the collection already\n",
    "collection_size = len(subjects)\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] Loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "print(\"[INFO] Model loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Capture images through web cam and detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter name for Subject #1: Andrew\n",
      "[INFO] Capturing the face of Subject #1...\n",
      "Processing Image 1...\n",
      "[INFO] Computing object detections...\n",
      "Image 1 processed.\n",
      "Processing Image 2...\n",
      "[INFO] Computing object detections...\n",
      "Image 2 processed.\n",
      "Processing Image 3...\n",
      "[INFO] Computing object detections...\n",
      "Image 3 processed.\n",
      "Processing Image 4...\n",
      "[INFO] Computing object detections...\n",
      "Image 4 processed.\n",
      "Processing Image 5...\n",
      "[INFO] Computing object detections...\n",
      "Image 5 processed.\n",
      "Processing Image 6...\n",
      "[INFO] Computing object detections...\n",
      "Image 6 processed.\n",
      "Processing Image 7...\n",
      "[INFO] Computing object detections...\n",
      "Image 7 processed.\n",
      "Processing Image 8...\n",
      "[INFO] Computing object detections...\n",
      "Image 8 processed.\n",
      "Processing Image 9...\n",
      "[INFO] Computing object detections...\n",
      "Image 9 processed.\n",
      "Processing Image 10...\n",
      "[INFO] Computing object detections...\n",
      "Image 10 processed.\n",
      "Processing Image 11...\n",
      "[INFO] Computing object detections...\n",
      "Image 11 processed.\n",
      "Processing Image 12...\n",
      "[INFO] Computing object detections...\n",
      "Image 12 processed.\n",
      "Processing Image 13...\n",
      "[INFO] Computing object detections...\n",
      "Image 13 processed.\n",
      "Processing Image 14...\n",
      "[INFO] Computing object detections...\n",
      "Image 14 processed.\n",
      "Processing Image 15...\n",
      "[INFO] Computing object detections...\n",
      "Image 15 processed.\n",
      "Processing Image 16...\n",
      "[INFO] Computing object detections...\n",
      "Image 16 processed.\n",
      "Processing Image 17...\n",
      "[INFO] Computing object detections...\n",
      "Image 17 processed.\n",
      "Processing Image 18...\n",
      "[INFO] Computing object detections...\n",
      "Image 18 processed.\n",
      "Processing Image 19...\n",
      "[INFO] Computing object detections...\n",
      "Image 19 processed.\n",
      "Processing Image 20...\n",
      "[INFO] Computing object detections...\n",
      "Image 20 processed.\n",
      "Processing Image 21...\n",
      "[INFO] Computing object detections...\n",
      "Image 21 processed.\n",
      "Processing Image 22...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 22...\n",
      "[INFO] Computing object detections...\n",
      "Image 22 processed.\n",
      "Processing Image 23...\n",
      "[INFO] Computing object detections...\n",
      "Image 23 processed.\n",
      "Processing Image 24...\n",
      "[INFO] Computing object detections...\n",
      "Image 24 processed.\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Processing Image 25...\n",
      "[INFO] Computing object detections...\n",
      "Image 25 processed.\n",
      "Processing Image 26...\n",
      "[INFO] Computing object detections...\n",
      "Image 26 processed.\n",
      "Processing Image 27...\n",
      "[INFO] Computing object detections...\n",
      "Image 27 processed.\n",
      "Processing Image 28...\n",
      "[INFO] Computing object detections...\n",
      "Image 28 processed.\n",
      "Processing Image 29...\n",
      "[INFO] Computing object detections...\n",
      "Image 29 processed.\n",
      "Processing Image 30...\n",
      "[INFO] Computing object detections...\n",
      "Image 30 processed.\n"
     ]
    }
   ],
   "source": [
    "#iterate through the subject\n",
    "for i in range(num_of_subject):\n",
    "    \n",
    "    #input subject name and append it to subjects\n",
    "    subject_name = input(\"Enter name for Subject #\" + str(i + collection_size) + \": \")\n",
    "    start_num = 0\n",
    "    \n",
    "    #if the input exists in subjects, no new entry will be appended\n",
    "    if subject_name in subjects:\n",
    "        subject_dir = out_dir + \"/s\" + str(subjects.index(subject_name))\n",
    "        sub_dir_obj = os.fsencode(subject_dir)\n",
    "        #iterate through the file names to find the correct starting index for new inputs\n",
    "        if len(os.listdir(sub_dir_obj) ) == 0:\n",
    "            break;\n",
    "        else:\n",
    "            for file in os.listdir(sub_dir_obj):\n",
    "                if file is not '':\n",
    "                    file_name_str = os.fsdecode(file).split('.')\n",
    "                    file_num = int(file_name_str[0])\n",
    "                    start_num = max(file_num, start_num)\n",
    "            start_num += 1   \n",
    "    #append new entry to subjects and create respective directory \n",
    "    else:\n",
    "        subjects.append(subject_name)\n",
    "        #create folder for each subject (if not exist)\n",
    "        subject_dir = out_dir + \"/s\" + str(i + collection_size)\n",
    "        if not os.path.exists(subject_dir):\n",
    "            os.makedirs(subject_dir)\n",
    "\n",
    "    #capture images of the subject until target number reached\n",
    "    n = 1\n",
    "    print(\"[INFO] Capturing the face of Subject #\" + str(i + collection_size) + \"...\")\n",
    "    while(cap.isOpened()):  # check !\n",
    "        # capture frame-by-frame  \n",
    "        if n <= image_per_subject:\n",
    "            ret, image = cap.read()\n",
    "            print('Processing Image %s...' % str(n))\n",
    "\n",
    "            # load the input image and construct an input blob for the image by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "            (h, w) = image.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "            # pass the blob through the network and obtain the detections and predictions\n",
    "            print(\"[INFO] Computing object detections...\")\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "\n",
    "            # loop over the detections\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                # extract the confidence (i.e., probability) associated with the prediction\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                # filter out weak detections by ensuring the 'confidence' is greater than the minimum confidence\n",
    "                if confidence > 0.95:\n",
    "                    # compute the (x, y)-coordinates of the bounding box for the object\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                    face = image[startY : endY, startX : endX]\n",
    "                    width, height, channels = face.shape\n",
    "                    if min(width, height) > 128:\n",
    "                        face = cv2.resize(face,(crop_size, crop_size))\n",
    "\n",
    "                    face = relight(face,random.uniform(0.5,1.5),random.randint(-50,50))\n",
    "                    cv2.imwrite(subject_dir + '/' + str(n + start_num) + '.jpg', face)\n",
    "                    print('Image %s processed.' % str(n))\n",
    "                    n += 1\n",
    "                key = cv2.waitKey(30) & 0xff\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "cap.release()   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare Training Data & Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Directory Structure Tree for Training Data:\n",
    "```\n",
    "training-data\n",
    "|-------------- s1\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "|-------------- s2\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "|-------------- sN\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 prepare_training_data() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #iterate through each subject's respective folder\n",
    "    for dir_name in dirs:\n",
    "\n",
    "        #ignore any directory not starting with 's'\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "\n",
    "        #extract label number by removing 's' in dir_name\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "        print(\"Training Subject #\" + str(label) + \": \")\n",
    "\n",
    "        #build path of directory containin images for current subject subject\n",
    "        #e.g. \"training-data/s1\"\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "\n",
    "        #get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "\n",
    "        for image_name in subject_images_names:\n",
    "            print(\"s\" + str(label) + \"/\" + image_name + \" completed.\")\n",
    "            \n",
    "            #create path to the image\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "            \n",
    "            # load the input image and convert it from BGR (OpenCV ordering)\n",
    "            # to dlib ordering (RGB)\n",
    "            image = cv2.imread(image_path)\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # detect the (x, y)-coordinates of the bounding boxes\n",
    "            # corresponding to each face in the input image\n",
    "            boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
    "\n",
    "            # compute the facial embedding for the face\n",
    "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "            # loop over the encodings\n",
    "            for encoding in encodings:\n",
    "                # add each encoding + name to our set of known names and\n",
    "                # encodings\n",
    "                knownEncodings.append(encoding)\n",
    "                knownNames.append(subjects[label])\n",
    "    \n",
    "    data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Prepare training data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Training model...\n",
      "Training Subject #1: \n",
      "s1/8.jpg completed.\n",
      "s1/9.jpg completed.\n",
      "s1/14.jpg completed.\n",
      "s1/28.jpg completed.\n",
      "s1/29.jpg completed.\n",
      "s1/15.jpg completed.\n",
      "s1/17.jpg completed.\n",
      "s1/16.jpg completed.\n",
      "s1/12.jpg completed.\n",
      "s1/13.jpg completed.\n",
      "s1/11.jpg completed.\n",
      "s1/10.jpg completed.\n",
      "s1/21.jpg completed.\n",
      "s1/20.jpg completed.\n",
      "s1/22.jpg completed.\n",
      "s1/23.jpg completed.\n",
      "s1/27.jpg completed.\n",
      "s1/26.jpg completed.\n",
      "s1/18.jpg completed.\n",
      "s1/24.jpg completed.\n",
      "s1/30.jpg completed.\n",
      "s1/25.jpg completed.\n",
      "s1/19.jpg completed.\n",
      "s1/4.jpg completed.\n",
      "s1/5.jpg completed.\n",
      "s1/7.jpg completed.\n",
      "s1/6.jpg completed.\n",
      "s1/2.jpg completed.\n",
      "s1/3.jpg completed.\n",
      "s1/1.jpg completed.\n",
      "[INFO] Model Training Completed.\n",
      "Total faces:  25\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Training model...\")\n",
    "data = prepare_training_data(\"./training-data\")\n",
    "print(\"[INFO] Model Training Completed.\")\n",
    "\n",
    "print(\"Total faces: \", len(data[\"encodings\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 recognize_faces() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(img_file):\n",
    "    \n",
    "    # load the input image and convert it from BGR to RGB\n",
    "    image = cv2.imread(img_file)\n",
    "    width, height, channels = image.shape\n",
    "    if min(width, height) > 1280:\n",
    "        image = imutils.resize(image, width = 1280)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # detect the (x, y)-coordinates of the bounding boxes corresponding \n",
    "    # to each face in the input image, then compute the facial embeddings for each face\n",
    "    print(\"[INFO] Recognizing faces...\")\n",
    "    boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "\n",
    "    # initialize the list of names for each face detected\n",
    "    names = []\n",
    "\n",
    "    # loop over the facial embeddings\n",
    "    for encoding in encodings:\n",
    "        # attempt to match each face in the input image to our known encodings\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # check to see if we have found a match\n",
    "        if True in matches:\n",
    "            # find the indexes of all matched faces then initialize a dictionary \n",
    "            # to count the total number of times each face was matched\n",
    "            matchedIdxs = [i for (i, b) in enumerate (matches) if b]\n",
    "            counts = {}\n",
    "\n",
    "            # loop over the matched indexes and maintain a count for each recognized face face\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "            # determine the recognized face with the largest number of votes\n",
    "            # (note: in the event of an unlikely tie Python will select first entry in the dictionary)\n",
    "            name = max(counts, key=counts.get)\n",
    "\n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "    \n",
    "    # loop over the recognized faces\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        # draw the predicted face name on the image\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Recognizing faces...\n",
      "[INFO] Recogonition Completed.\n"
     ]
    }
   ],
   "source": [
    "# recognize test image\n",
    "image = recognize_faces(\"test-data/test3.jpg\")\n",
    "print(\"[INFO] Recogonition Completed.\")\n",
    "\n",
    "# show the out put image \n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
