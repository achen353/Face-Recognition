{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and packages needed\n",
    "import sys, os, dlib, glob, pickle, face_recognition, cv2, random\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create label collection: subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the directories (one directory for each subject) in data folder\n",
    "dirs = os.listdir(\"./training-data\")\n",
    "\n",
    "# initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "#there is no label 0 in our training data so subject name for index/label 0 is empty\n",
    "subjects = [\"\", \"Hulk\", \"Iron Man\", \"Spider-man\", \"Thor\", \"Winter Soldier\", \"Ant-man\", \"Scarlet Witch\", \"Hawkeye\", \"Agent Sharon Carter\", \"Captain America\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Collect Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison on different face detection:\n",
    "\n",
    "https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 relight() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改變亮度與對比\n",
    "def relight(img,alpha = 1,bias = 0):\n",
    "    w, h = img.shape[:2]\n",
    "\n",
    "    for i in range(0,w):\n",
    "        for j in range(0,h):\n",
    "            for c in range(3):\n",
    "                tmp = int(img[i,j,c] * alpha + bias)\n",
    "                if tmp > 255:\n",
    "                    tmp = 255\n",
    "                elif tmp < 0:\n",
    "                    tmp = 0\n",
    "                img[i,j,c] = tmp\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 training-data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create directory for training data\n",
    "out_dir = \"./training-data\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Input specifics of data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input number of subject\n",
    "num_of_subject = int(input(\"Enter the number of subject(s): \"))\n",
    "#input number of images per subject\n",
    "image_per_subject = int(input(\"Enter the number of image per subject: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Import model and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#set cropping size for the images captured\n",
    "crop_size = 128\n",
    "\n",
    "#check if there's any label/face in the collection already\n",
    "collection_size = len(subjects)\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] Loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "print(\"[INFO] Model loaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Capture images through web cam and detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through the subject\n",
    "for i in range(num_of_subject):\n",
    "    \n",
    "    #input subject name and append it to subjects\n",
    "    subject_name = input(\"Enter name for Subject #\" + str(i + collection_size) + \": \")\n",
    "    start_num = 0\n",
    "    \n",
    "    #if the input exists in subjects, no new entry will be appended\n",
    "    if subject_name in subjects:\n",
    "        subject_dir = out_dir + \"/s\" + str(subjects.index(subject_name))\n",
    "        sub_dir_obj = os.fsencode(subject_dir)\n",
    "        #iterate through the file names to find the correct starting index for new inputs\n",
    "        if len(os.listdir(sub_dir_obj) ) == 0:\n",
    "            break;\n",
    "        else:\n",
    "            for file in os.listdir(sub_dir_obj):\n",
    "                if file is not '':\n",
    "                    file_name_str = os.fsdecode(file).split('.')\n",
    "                    file_num = int(file_name_str[0])\n",
    "                    start_num = max(file_num, start_num)\n",
    "            start_num += 1   \n",
    "    #append new entry to subjects and create respective directory \n",
    "    else:\n",
    "        subjects.append(subject_name)\n",
    "        #create folder for each subject (if not exist)\n",
    "        subject_dir = out_dir + \"/s\" + str(i + collection_size)\n",
    "        if not os.path.exists(subject_dir):\n",
    "            os.makedirs(subject_dir)\n",
    "    \n",
    "    #capture images of the subject until target number reached\n",
    "    n = 1\n",
    "    print(\"[INFO] Capturing the face of Subject #\" + str(i + collection_size) + \"...\")\n",
    "    while(cap.isOpened()):  # check !\n",
    "        # capture frame-by-frame  \n",
    "        if n <= image_per_subject:\n",
    "            ret, image = cap.read()\n",
    "            print('Processing Image %s...' % str(n))\n",
    "            \n",
    "            # load the input image and construct an input blob for the image by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "            (h, w) = image.shape[:2]\n",
    "            blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "            \n",
    "            # pass the blob through the network and obtain the detections and predictions\n",
    "            print(\"[INFO] Computing object detections...\")\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "            \n",
    "            # loop over the detections\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                # extract the confidence (i.e., probability) associated with the prediction\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "\n",
    "                # filter out weak detections by ensuring the `confidence` is\n",
    "                # greater than the minimum confidence\n",
    "                if confidence > 0.95:\n",
    "                    # compute the (x, y)-coordinates of the bounding box for the\n",
    "                    # object\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                    face = image[startY : endY, startX : endX]\n",
    "                    face = cv2.resize(face,(crop_size, crop_size))\n",
    "\n",
    "                    face = relight(face,random.uniform(0.5,1.5),random.randint(-50,50))\n",
    "                    cv2.imwrite(subject_dir + '/' + str(n + start_num) + '.jpg', face)\n",
    "                    print('Image %s processed.' % str(n))\n",
    "                    n += 1\n",
    "                key = cv2.waitKey(30) & 0xff\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare Training Data & Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Directory Structure Tree for Training Data:\n",
    "```\n",
    "training-data\n",
    "|-------------- s1\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "|-------------- s2\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "|-------------- sN\n",
    "|               |-- 1.jpg\n",
    "|               |-- ...\n",
    "|               |-- k.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 prepare_training_data() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #iterate through each subject's respective folder\n",
    "    for dir_name in dirs:\n",
    "\n",
    "        #ignore any directory not starting with 's'\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "\n",
    "        #extract label number by removing 's' in dir_name\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "        print(\"Training Subject #\" + str(label) + \": \")\n",
    "\n",
    "        #build path of directory containin images for current subject subject\n",
    "        #e.g. \"training-data/s1\"\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "\n",
    "        #get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "\n",
    "        for image_name in subject_images_names:\n",
    "            print(\"s\" + str(label) + \"/\" + image_name + \" completed.\")\n",
    "            \n",
    "            #create path to the image\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "            \n",
    "            # load the input image and convert it from BGR (OpenCV ordering)\n",
    "            # to dlib ordering (RGB)\n",
    "            image = cv2.imread(image_path)\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # detect the (x, y)-coordinates of the bounding boxes\n",
    "            # corresponding to each face in the input image\n",
    "            boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
    "\n",
    "            # compute the facial embedding for the face\n",
    "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "            # loop over the encodings\n",
    "            for encoding in encodings:\n",
    "                # add each encoding + name to our set of known names and\n",
    "                # encodings\n",
    "                knownEncodings.append(encoding)\n",
    "                knownNames.append(subjects[label])\n",
    "    \n",
    "    data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Prepare training data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[Info] Training model...\")\n",
    "data = prepare_training_data(\"./training-data\")\n",
    "print(\"[INFO] Model Training Completed.\")\n",
    "\n",
    "print(\"Total faces: \", len(data[\"encodings\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 recognize_faces() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(img_file):\n",
    "    \n",
    "    # load the input image and convert it from BGR to RGB\n",
    "    image = cv2.imread(\"test-data/test1.jpg\")\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # detect the (x, y)-coordinates of the bounding boxes corresponding \n",
    "    # to each face in the input image, then compute the facial embeddings for each face\n",
    "    print(\"[INFO] Recognizing faces...\")\n",
    "    boxes = face_recognition.face_locations(rgb, model = \"cnn\")\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "\n",
    "    # initialize the list of names for each face detected\n",
    "    names = []\n",
    "\n",
    "    # loop over the facial embeddings\n",
    "    for encoding in encodings:\n",
    "        # attempt to match each face in the input image to our known encodings\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # check to see if we have found a match\n",
    "        if True in matches:\n",
    "            # find the indexes of all matched faces then initialize a\n",
    "            # dictionary to count the total number of times each face\n",
    "            # was matched\n",
    "            matchedIdxs = [i for (i, b) in enumerate (matches) if b]\n",
    "            counts = {}\n",
    "\n",
    "            # loop over the matched indexes and maintain a count for\n",
    "            # each recognized face face\n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "            # determine the recognized face with the largest number of\n",
    "            # votes (note: in the event of an unlikely tie Python will\n",
    "            # select first entry in the dictionary)\n",
    "            name = max(counts, key=counts.get)\n",
    "\n",
    "        # update the list of names\n",
    "        names.append(name)\n",
    "    \n",
    "    # loop over the recognized faces\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        # draw the predicted face name on the image\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize test image\n",
    "image = recognize_faces(\"test-data/test1.jpg\")\n",
    "print(\"[INFO] Recogonition Completed.\")\n",
    "\n",
    "# show the out put image \n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
